# -*- coding: utf-8 -*-
"""CapstoneMLP4Classes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XWr077gsB5xpTtfAOEmqRZfzc9tBOQF7

# Data Understanding

Import Library
"""

import pandas as pd
import numpy as np
import joblib
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.ensemble import RandomForestClassifier

import pandas as pd
import numpy as np

# Baca file dengan argumen na_values
df = pd.read_csv('data.csv', na_values=['', ' ', 'NA', 'NaN', 'null', 'None'])
df

df.info()

# Drop kolom dengan jumlah non-null kurang dari 1200
df = df.drop(columns=[col for col in df.columns if df[col].count() < 1200])

# Pilih kolom numerik
import matplotlib.pyplot as plt
numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns
# Tentukan ukuran figure dan grid
plt.figure(figsize=(18, 15))
df[numerical_cols].hist(bins=20, layout=(6, 5), figsize=(18, 15), edgecolor='black')
plt.tight_layout()
plt.suptitle("Distribusi Fitur Numerikal", fontsize=20, y=1.02)
plt.show()

df.info()

df.nunique()

min_max_df = pd.DataFrame({
    'Min': df.min(numeric_only=True),
    'Max': df.max(numeric_only=True)
})
min_max_df

"""DROP NAN DAN KOLOM TIDAK DIGUNAKAN"""

df.drop(['ClientID', 'CycleNumber', 'ReproductiveCategory', 'Group', 'MensesScoreDayOne', 'MensesScoreDayTwo', 'MensesScoreDayThree', 'MensesScoreDayFour', 'MensesScoreDayFive', 'TotalMensesScore'], axis=1, inplace=True)
df.dropna(inplace=True)
df.reset_index(drop=True, inplace=True)

df.info()

df.describe(include='all').T

df.nunique()

np.random.seed(42)

# 1. Tambahkan fitur buatan
df['StressScore'] = np.random.randint(1, 6, len(df))
df['DietScore'] = np.random.randint(1, 6, len(df))
df['MedicalConditionScore'] = np.random.randint(1, 6, len(df))

# 2. Ubah target numerik menjadi kategori
def classify_cycle(length):
    if 21 <= length <= 25:
        return 'Normal Pendek'
    elif 26 <= length <= 30:
        return 'Normal Sedang'
    elif 31 <= length <= 35:
        return 'Normal Panjang'
    else:
        return 'Tidak Normal'

df['CycleCategory'] = df['LengthofCycle'].apply(classify_cycle)

# 3. Definisikan fitur dan target klasifikasi
X = df.drop(columns=['LengthofCycle', 'CycleCategory',])
y = df['CycleCategory']

smote = SMOTE(random_state=42)
X_smote, y_smote = smote.fit_resample(X, y)

y_smote.value_counts()

encoder = LabelEncoder()
y_encoder = encoder.fit_transform(y_smote)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import StandardScaler

# Normalisasi fitur
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_smote)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoder, test_size=0.2, random_state=42, stratify=y_encoder)

print(len(X_test))
print(len(X_train))

# Buat model MLP
model = Sequential([
    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.3),
    Dense(64, activation='relu'),
    Dropout(0.3),
    Dense(len(np.unique(y_encoder)), activation='softmax')  # output neurons = jumlah kelas
])

# Kompilasi model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Training
history = model.fit(X_train, y_train, epochs=100, batch_size=32,
                    validation_split=0.2, verbose=1)

# Evaluasi
loss, accuracy = model.evaluate(X_test, y_test)
print(f'\nTest Accuracy: {accuracy:.4f}')

# Prediksi dan klasifikasi report
y_pred = np.argmax(model.predict(X_test), axis=1)
print("=== Confusion Matrix ===")
print(confusion_matrix(y_test, y_pred))
print("=== Classification Report ===")
print(classification_report(y_test, y_pred))

# Plot Akurasi
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy', color='blue')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='green')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)

# Plot Loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss', color='red')
plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

# Simpan model
model.save('mlp_model.h5')
joblib.dump(scaler, 'scaler.pkl')
joblib.dump(encoder, 'encoder.pkl')